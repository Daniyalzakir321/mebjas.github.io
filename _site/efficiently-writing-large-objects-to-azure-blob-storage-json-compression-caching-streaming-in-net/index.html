<!DOCTYPE html>
<html lang="en">
 <head>
 <meta charset="utf-8">
 <meta http-equiv="X-UA-Compatible" content="IE=edge">
 <meta name="viewport" content="width=device-width, initial-scale=1">
 <meta name="google-site-verification" content="Xs4Y8kOjxCHZvery6v-Y6yVIptmWsSjownRLWpRDDlc" />
 <meta name="msvalidate.01" content="C21F82032619E6AE38AEC7FFE4D05827" />
<link rel="stylesheet" href=/assets/main.css>
<link rel="stylesheet" href=/assets/custom.css>
<link rel="alternate" type="application/rss+xml" title="Minhaz&#39;s Blog" href="/feed.xml">
<link rel="shortcut icon" href=/assets/favicon.ico>
<link rel="icon" type="image/png" sizes="32x32" href=/assets/favicon.ico>
  <script src="/assets/js/jquery.js"></script>
<title>Efficiently writing large objects to Azure Blob Storage – JSON, Compression, Caching, Streaming in .Net | Minhaz’s Blog</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Efficiently writing large objects to Azure Blob Storage – JSON, Compression, Caching, Streaming in .Net" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Azure Storage Blob is an Azure Storage offering that allows you to store giga bytes of data in from hundreds to billions of objects in hot, cool, or archive tiers, depending on how often data access is needed. Store any type of unstructured data—images, videos, audio, documents and more—easily and cost-effectively. These features make it a strong candidate for storing serialized Machine Learning Models if you have models per tenant. But, if the application is READ + WRITE heavy and the size of objects are large it can lead to a variety of issues, primarily: &lt;ol&gt;&lt;li&gt;Large I/O calls&lt;/li&gt;&lt;li&gt;OutOfMemory Exceptions (OOM)&lt;/li&gt;&lt;/ol&gt; In this article I have explained why the issues occur and what are the ways to mitigate them." />
<meta property="og:description" content="Azure Storage Blob is an Azure Storage offering that allows you to store giga bytes of data in from hundreds to billions of objects in hot, cool, or archive tiers, depending on how often data access is needed. Store any type of unstructured data—images, videos, audio, documents and more—easily and cost-effectively. These features make it a strong candidate for storing serialized Machine Learning Models if you have models per tenant. But, if the application is READ + WRITE heavy and the size of objects are large it can lead to a variety of issues, primarily: &lt;ol&gt;&lt;li&gt;Large I/O calls&lt;/li&gt;&lt;li&gt;OutOfMemory Exceptions (OOM)&lt;/li&gt;&lt;/ol&gt; In this article I have explained why the issues occur and what are the ways to mitigate them." />
<link rel="canonical" href="http://localhost:4000/efficiently-writing-large-objects-to-azure-blob-storage-json-compression-caching-streaming-in-net/" />
<meta property="og:url" content="http://localhost:4000/efficiently-writing-large-objects-to-azure-blob-storage-json-compression-caching-streaming-in-net/" />
<meta property="og:site_name" content="Minhaz’s Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-04-03T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Efficiently writing large objects to Azure Blob Storage – JSON, Compression, Caching, Streaming in .Net" />
<meta name="twitter:site" content="@minhazav" />
<meta name="twitter:creator" content="@minhazav" />
<script type="application/ld+json">
{"headline":"Efficiently writing large objects to Azure Blob Storage – JSON, Compression, Caching, Streaming in .Net","dateModified":"2018-04-03T00:00:00+00:00","datePublished":"2018-04-03T00:00:00+00:00","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://blog.minhazav.dev/images/rsz_self_1_1.jpg"}},"@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/efficiently-writing-large-objects-to-azure-blob-storage-json-compression-caching-streaming-in-net/"},"url":"http://localhost:4000/efficiently-writing-large-objects-to-azure-blob-storage-json-compression-caching-streaming-in-net/","description":"Azure Storage Blob is an Azure Storage offering that allows you to store giga bytes of data in from hundreds to billions of objects in hot, cool, or archive tiers, depending on how often data access is needed. Store any type of unstructured data—images, videos, audio, documents and more—easily and cost-effectively. These features make it a strong candidate for storing serialized Machine Learning Models if you have models per tenant. But, if the application is READ + WRITE heavy and the size of objects are large it can lead to a variety of issues, primarily: &lt;ol&gt;&lt;li&gt;Large I/O calls&lt;/li&gt;&lt;li&gt;OutOfMemory Exceptions (OOM)&lt;/li&gt;&lt;/ol&gt; In this article I have explained why the issues occur and what are the ways to mitigate them.","@context":"https://schema.org"}</script>
</head>
 <body data-instant-allow-query-string data-instant-allow-external-links>
  <header class="site-header">
   <div class="wrapper-header">
     <div class="header-left">
       <div>
          <a class="site-title" href="/">
            <b>Minhaz's Blog</b>
          </a>
       </div>
       <div>
          <a class="site-subtitle" href="/">
            <b>Hack your way out!</b>
          </a>
       </div>
     </div>
     <div class="header-right">
        <a class="page-link" href="https://github.com/mebjas">Github</a>
        <a class="page-link" href="https://www.linkedin.com/in/minhazav">LinkedIn</a>
        <a class="page-link" href="/about/">About Me</a>
        <a class="page-link" href="/photography/">Photography</a>
     </div>
   </div>
 </header>
   <main class="default-content" aria-label="Content">
     <div class="wrapper-content">
       <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
<header class="page-header">
   <h1 class="post-title" itemprop="name headline">Efficiently writing large objects to Azure Blob Storage – JSON, Compression, Caching, Streaming in .Net</h1>
   <p class="post-meta">
      <time datetime="2018-04-03T00:00:00+00:00" itemprop="datePublished">
        Apr 3, 2018
      </time>
      •
<a class="category-link" href="/category/architecture/" rel="category">architecture</a> 
<a class="category-link" href="/category/system-design/" rel="category">system-design</a> 
<a class="category-link" href="/category/azure/" rel="category">azure</a> 
<a class="category-link" href="/category/azure-storage-blob/" rel="category">azure-storage-blob</a> 
<a class="category-link" href="/category/compression/" rel="category">compression</a> 
<a class="category-link" href="/category/distributed-systems/" rel="category">distributed-systems</a> 
<a class="category-link" href="/category/machine-learning/" rel="category">machine-learning</a> 
<a class="category-link" href="/category/microsoft/" rel="category">microsoft</a> 
   </p>
 </header>
 <div class="post-content" itemprop="articleBody">
   <h2 id="introduction-azure-storage-blob">Introduction: Azure Storage Blob</h2>
<p>Azure Storage Blob is an Azure Storage offering that allows you to store GigaBytes of data in from hundreds to billions of objects in hot, cool, or archive tiers, depending on how often data access is needed. Store any type of unstructured data—images, videos, audio, documents and more—easily and cost-effectively.
Reference: https://azure.microsoft.com/en-in/services/storage/blobs/</p>
<p>In the latest offering it comes with <strong>strong consistency, geo redundant storage, multiple blob types (Block Blob vs Page Blob vs Append Blob)</strong>. There is also option to update portion of blobs thus making it bandwidth efficient if used as such. Azure guarantees <code class="highlighter-rouge">99.99% up-time</code> and have support for reading from secondary region in case of failure (Eventual consistency).</p>
<h2 id="the-problem">The problem</h2>
<p>These features make it a strong candidate for storing serialized Machine Learning Models if you have models per tenant. But, if the application is READ + WRITE heavy and the size of objects are large it can lead to a variety of issues, primarily:</p>
<h3 id="large-io-calls">Large I/O calls</h3>
<p>If the size of objects that are persisted and read from the blob is large, the process will spend decent amount of time and network bandwidth in uploading and downloading data respectively from blob.</p>
<p><img src="../images/post8_image1.png" alt="Service Level Agreement (SLA) guarantees on uploading and downloading blobs" width="750px" /><br />
<span class="image-caption"><em>Figure: Service Level Agreement (SLA) guarantees on uploading and downloading blobs.</em></span></p>
<p>If not properly implemented this could lead to low throughput and large overall processing time. If you are dealing with a 100 Mb serialized file – it could take upto <code class="highlighter-rouge">200 seconds</code> (worst case!).</p>
<h3 id="outofmemory-exceptions-oom">OutOfMemory Exceptions (OOM)</h3>
<p>JSON is very popular schema for serializing objects for persistence and transport. There are a variety of libraries available for serializing and de-serializing objects in <code class="highlighter-rouge">.net</code>. However, when dealing with really large objects you can encounter out of memory issues.</p>
<h4 id="primary-causes">Primary causes:</h4>
<p>The Common Language Runtime (CLR) cannot allocate enough contiguous memory to successfully perform an operation. This exception can be thrown by any property assignment or method call that requires a memory allocation. Following cases are popular reasons for OOM exceptions:</p>
<ul>
 <li><strong>Your app runs as a <code class="highlighter-rouge">32-bit process</code></strong>: 32-bit processes can allocate a maximum of <code class="highlighter-rouge">2GB</code> of virtual user-mode memory on <code class="highlighter-rouge">32-bit</code> systems, and <code class="highlighter-rouge">4GB</code> of virtual user-mode memory on <code class="highlighter-rouge">64-bit</code> systems. This can make it more difficult for the common language runtime to allocate sufficient contiguous memory when a large allocation is needed. In contrast, <strong><code class="highlighter-rouge">64-bit</code> processes can allocate up to <code class="highlighter-rouge">8TB</code> of virtual memory</strong>. This kind of issues are particularly popular when testing code in debug environment in local system.</li>
 <li><strong>Lack of available memory due to memory leaks</strong>: Although the garbage collector is able to free memory allocated to managed types, it does not manage memory allocated to unmanaged resources such as operating system handles (including handles to files, memory-mapped files, pipes, registry keys, and wait handles) and memory blocks allocated directly by Windows API calls or by calls to memory allocation functions such as malloc.</li>
 <li><strong>You are repeatedly concatenating large strings</strong>: Because strings are immutable, each string concatenation operation creates a new string. The impact for small strings, or for a small number of concatenation operations, is negligible. But for large strings or a very large number of concatenation operations, string concatenation can lead to a large number of memory allocations and memory fragmentation, poor performance, and possibly OutOfMemoryExceptionexceptions.</li>
 <li>And many more: <a href="https://msdn.microsoft.com/en-us/library/system.outofmemoryexception(v=vs.110).aspx">MSDN Detailed Documentation on OOM Exception</a>.</li>
</ul>
<h2 id="solutions">Solutions</h2>
<p><img src="../images/post8_image2.jpg" alt="The Goal - Efficiency &amp; Throughput" width="750px" /><br />
<span class="image-caption"><em>Figure: The Goal – Efficiency &amp; Throughput</em></span></p>
<p>So far I have experimented with following ways to improve efficiency and throughput of the system using Azure Storage Blob:</p>
<h3 id="json-serialization--de-serialization-libraries">JSON Serialization &amp; De-serialization libraries</h3>
<p>A lot of libraries are available in <code class="highlighter-rouge">.net</code> to deal with JSON format – primarily serialization and de-serialization. <code class="highlighter-rouge">JSON.Net</code> is the most popular package available. While it comes with a lot of features it’s not necessarily the fastest library out there. However, you need to ensure if other libraries works best for you. Based on performance tests I did results looked like this:</p>
<p><img src="../images/post8_image3.png" alt="Performance of different JSON libraries in .Net" width="500px" /><br />
<span class="image-caption"><em>Figure: Performance of different JSON libraries in .Net</em></span></p>
<p><a href="https://github.com/mebjas/DotNetTests/tree/master/JSONSerializationDesrialization">Sample Code for this test</a> is available on Github. However, the difference is not much given the richness of features that comes with <code class="highlighter-rouge">JSON.Net</code>.</p>
<h3 id="compression--lower-io-more-cpu">Compression – Lower I/O more CPU</h3>
<p>The amount of time to download / upload data to blob can be considered proportional to the size of object in question. Thus, a machine will spend decent amount of time in I/O if the size of objects are large. Generally, the flow is:</p><pre><code class="language-cmd"># Saving the model
.Net Objects &gt; Serialized to JSON String &gt; Upload to blob

# Reading the model
Download from Blob &gt; Deserialize the JSON String &gt; .Net Objects
</code></pre>
<p>Now if the size of object is large, compression can come in really handy. For JSON Strings GZIP can give as good as 10:1 compression ratio. This can help reduce I/O time and increase CPU cycles – thus increase the throughput and efficiency of the system.</p>
<h4 id="code-example">Code example</h4>
<p><strong>Saving the model: you can zip and upload data to blob without double serialization</strong></p>
<div class="language-csharp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">public</span> <span class="k">void</span> <span class="nf">UploadDataModel</span><span class="p">(</span><span class="n">DataModel</span> <span class="n">model</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">MemoryStream</span> <span class="n">stream</span> <span class="p">=</span> <span class="k">new</span> <span class="nf">MemoryStream</span><span class="p">();</span>
    <span class="k">using</span> <span class="p">(</span><span class="kt">var</span> <span class="n">sw</span> <span class="p">=</span> <span class="k">new</span> <span class="nf">StreamWriter</span><span class="p">(</span><span class="n">stream</span><span class="p">))</span>
    <span class="k">using</span> <span class="p">(</span><span class="n">JsonWriter</span> <span class="n">writer</span> <span class="p">=</span> <span class="k">new</span> <span class="nf">JsonTextWriter</span><span class="p">(</span><span class="n">sw</span><span class="p">))</span>
    <span class="p">{</span>
        <span class="kt">var</span> <span class="n">serializer</span> <span class="p">=</span> <span class="k">new</span> <span class="nf">JsonSerializer</span><span class="p">();</span>
        <span class="n">serializer</span><span class="p">.</span><span class="nf">Serialize</span><span class="p">(</span><span class="n">writer</span><span class="p">,</span> <span class="n">model</span><span class="p">);</span>
        <span class="n">sw</span><span class="p">.</span><span class="nf">Flush</span><span class="p">();</span>
        <span class="n">stream</span><span class="p">.</span><span class="n">Position</span> <span class="p">=</span> <span class="m">0</span><span class="p">;</span>

        <span class="k">using</span> <span class="p">(</span><span class="kt">var</span> <span class="n">mso</span> <span class="p">=</span> <span class="k">new</span> <span class="nf">MemoryStream</span><span class="p">())</span>
        <span class="p">{</span>
            <span class="k">using</span> <span class="p">(</span><span class="kt">var</span> <span class="n">gs</span> <span class="p">=</span> <span class="k">new</span> <span class="nf">GZipStream</span><span class="p">(</span><span class="n">mso</span><span class="p">,</span> <span class="n">CompressionMode</span><span class="p">.</span><span class="n">Compress</span><span class="p">))</span>
            <span class="p">{</span>
                <span class="nf">CopyTo</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span> <span class="n">gs</span><span class="p">);</span>
            <span class="p">}</span>

            <span class="n">mso</span><span class="p">.</span><span class="nf">Flush</span><span class="p">();</span>
            <span class="kt">byte</span><span class="p">[]</span> <span class="n">data</span> <span class="p">=</span> <span class="n">mso</span><span class="p">.</span><span class="nf">ToArray</span><span class="p">();</span>
            <span class="n">CloudBlockBlob</span> <span class="n">blockBlob</span> <span class="p">=</span> <span class="n">cloudBlobContainer</span><span class="p">.</span><span class="nf">GetBlockBlobReference</span><span class="p">(</span><span class="n">blobName</span><span class="p">);</span>
            <span class="n">blockBlob</span><span class="p">.</span><span class="nf">UploadFromByteArray</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="m">0</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">Length</span><span class="p">);</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="k">void</span> <span class="nf">CopyTo</span><span class="p">(</span><span class="n">Stream</span> <span class="n">src</span><span class="p">,</span> <span class="n">Stream</span> <span class="n">dest</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">byte</span><span class="p">[]</span> <span class="n">bytes</span> <span class="p">=</span> <span class="k">new</span> <span class="kt">byte</span><span class="p">[</span><span class="m">4096</span><span class="p">];</span>
    <span class="kt">int</span> <span class="n">cnt</span><span class="p">;</span>
    <span class="k">while</span> <span class="p">((</span><span class="n">cnt</span> <span class="p">=</span> <span class="n">src</span><span class="p">.</span><span class="nf">Read</span><span class="p">(</span><span class="n">bytes</span><span class="p">,</span> <span class="m">0</span><span class="p">,</span> <span class="n">bytes</span><span class="p">.</span><span class="n">Length</span><span class="p">))</span> <span class="p">!=</span> <span class="m">0</span><span class="p">)</span>
    <span class="p">{</span>
        <span class="n">dest</span><span class="p">.</span><span class="nf">Write</span><span class="p">(</span><span class="n">bytes</span><span class="p">,</span> <span class="m">0</span><span class="p">,</span> <span class="n">cnt</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>
<p><strong>Downloading the model: you can unzip and download data from blob without double de-serialization</strong></p>
<div class="language-csharp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">public</span> <span class="n">DataModel</span> <span class="nf">BlobToMemoryStream</span><span class="p">(</span><span class="kt">string</span> <span class="n">blobName</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">CloudBlockBlob</span> <span class="n">blockBlob</span> <span class="p">=</span> <span class="n">cloudBlobContainer</span><span class="p">.</span><span class="nf">GetBlockBlobReference</span><span class="p">(</span><span class="n">blobName</span><span class="p">);</span>
    <span class="k">using</span> <span class="p">(</span><span class="n">MemoryStream</span> <span class="n">ms</span> <span class="p">=</span> <span class="k">new</span> <span class="nf">MemoryStream</span><span class="p">())</span>
    <span class="p">{</span>
        <span class="n">blockBlob</span><span class="p">.</span><span class="nf">DownloadToStream</span><span class="p">(</span><span class="n">ms</span><span class="p">);</span>
        <span class="n">ms</span><span class="p">.</span><span class="nf">Seek</span><span class="p">(</span><span class="m">0</span><span class="p">,</span> <span class="n">SeekOrigin</span><span class="p">.</span><span class="n">Begin</span><span class="p">);</span>
        <span class="n">ms</span><span class="p">.</span><span class="nf">Flush</span><span class="p">();</span>
        <span class="n">ms</span><span class="p">.</span><span class="n">Position</span> <span class="p">=</span> <span class="m">0</span><span class="p">;</span>
        <span class="kt">byte</span><span class="p">[]</span> <span class="n">data</span> <span class="p">=</span> <span class="n">ms</span><span class="p">.</span><span class="nf">ToArray</span><span class="p">();</span>
        
        <span class="k">using</span> <span class="p">(</span><span class="kt">var</span> <span class="n">msi</span> <span class="p">=</span> <span class="k">new</span> <span class="nf">MemoryStream</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
        <span class="k">using</span> <span class="p">(</span><span class="kt">var</span> <span class="n">mso</span> <span class="p">=</span> <span class="k">new</span> <span class="nf">MemoryStream</span><span class="p">())</span>
        <span class="p">{</span>
            <span class="k">using</span> <span class="p">(</span><span class="kt">var</span> <span class="n">gs</span> <span class="p">=</span> <span class="k">new</span> <span class="nf">GZipStream</span><span class="p">(</span><span class="n">msi</span><span class="p">,</span> <span class="n">CompressionMode</span><span class="p">.</span><span class="n">Decompress</span><span class="p">))</span>
            <span class="p">{</span>
                <span class="nf">CopyTo</span><span class="p">(</span><span class="n">gs</span><span class="p">,</span> <span class="n">mso</span><span class="p">);</span>
            <span class="p">}</span>

            <span class="kt">string</span> <span class="n">jsonString</span> <span class="p">=</span> <span class="n">Encoding</span><span class="p">.</span><span class="n">UTF8</span><span class="p">.</span><span class="nf">GetString</span><span class="p">(</span><span class="n">mso</span><span class="p">.</span><span class="nf">ToArray</span><span class="p">());</span>
            <span class="n">msi</span><span class="p">.</span><span class="nf">Dispose</span><span class="p">();</span>
            <span class="k">return</span> <span class="n">JsonConvert</span><span class="p">.</span><span class="n">DeserializeObject</span><span class="p">&lt;</span><span class="n">DataModel</span><span class="p">&gt;(</span><span class="n">jsonString</span><span class="p">);</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="k">void</span> <span class="nf">CopyTo</span><span class="p">(</span><span class="n">Stream</span> <span class="n">src</span><span class="p">,</span> <span class="n">Stream</span> <span class="n">dest</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">byte</span><span class="p">[]</span> <span class="n">bytes</span> <span class="p">=</span> <span class="k">new</span> <span class="kt">byte</span><span class="p">[</span><span class="m">4096</span><span class="p">];</span>
    <span class="kt">int</span> <span class="n">cnt</span><span class="p">;</span>
    <span class="k">while</span> <span class="p">((</span><span class="n">cnt</span> <span class="p">=</span> <span class="n">src</span><span class="p">.</span><span class="nf">Read</span><span class="p">(</span><span class="n">bytes</span><span class="p">,</span> <span class="m">0</span><span class="p">,</span> <span class="n">bytes</span><span class="p">.</span><span class="n">Length</span><span class="p">))</span> <span class="p">!=</span> <span class="m">0</span><span class="p">)</span>
    <span class="p">{</span>
        <span class="n">dest</span><span class="p">.</span><span class="nf">Write</span><span class="p">(</span><span class="n">bytes</span><span class="p">,</span> <span class="m">0</span><span class="p">,</span> <span class="n">cnt</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>
<h4 id="caveat-of-this-approach">Caveat of this approach</h4>
<p>The steps involved in this can be very costly with respect to CPU time and thus the overall processing time if the objects are really large. This is however caused by lot of redundant information in the serialized string data. Thus can be solved by writing a custom serializer that serialized data to <code class="highlighter-rouge">byte array</code> and an opposite deserializer. This would <strong>decrease the size of serialized data and compression time drastically</strong> but could be <strong>difficult to maintain</strong> as compared to simply using some standard serialization approach.</p>
<h3 id="caching--in-memory-private-caching">Caching – In Memory Private caching</h3>
<p>If you are working with same data again and again you can reduce the no of time you have download the data from Azure Storage Blob by implementing a simple in memory cache. However, this has it’s own set of limitations – it can come in handy if the size of the objects can grow really large and your system can handle concurrency.</p>
<p>In this post I’ll share how to use in memory cache but note that for highly distributed systems with multiple nodes shared caches could be a good solution in many cases – but is out of scope of this article. The flow for In Memory Caching would be something like this:</p>
<p><img src="../images/post8_image4.png" alt="Abstract Architecture for In Memory caching" width="750px" /><br />
<span class="image-caption"><em>Figure: Abstract Architecture for In Memory caching</em></span></p>
<p><a href="https://msdn.microsoft.com/en-us/library/system.runtime.caching.memorycache(v=vs.110).aspx">MemoryCache Class</a> is available in .Net &amp; can be leverage for this purpose. Memory cache provides abstraction to store data in named caches in memory. It supports couple of features on top of that like:</p>
<ol>
 <li>Support for different eviction policies.</li>
 <li>Callbacks on eviction</li>
 <li>Restrictions on percentage of total memory or absolute memory usage.</li>
 <li>Option to store data as .Net objects in Memory
There is a <a href="https://msdn.microsoft.com/en-us/library/system.runtime.caching.memorycache(v=vs.110).aspx">very good read here</a>, if you are interested in learning more.</li>
</ol>
<h4 id="pros">Pros</h4>
<ol>
 <li>Improve efficiency by reducing I/O involved with downloading data from Azure Storage Blob.</li>
 <li>Leverage available memory with virtual machines.</li>
</ol>
<h4 id="cons">Cons</h4>
<ol>
 <li>Can lead to Out of Memory exceptions if not handled appropriately.</li>
 <li>Data still need to be persisted to blob storage as cache is volatile in nature.</li>
 <li>In case of multiple worker roles or nodes – the cache miss could be much greater than cache hit; It might not be as useful.</li>
</ol>
<p>All that said, using private cache can come in really handy if coupled with partitioned queues available with Service Bus queues.</p>
<h3 id="streaming--work-with-streams">Streaming – work with streams</h3>
<p>Most naive approach to working with Blobs could be:</p><pre><code class="language-cmd"># Saving to blob
DataModel &gt; Serialization to JSON String &gt; convert to bytes []
    &gt; Zip to byte[] &gt; Serialize &gt; Upload to blob as string

# Reading from blob
Download from blob to string &gt; Deserialize to byte[] 
    &gt; Unzip to byte [] &gt; Deserialize to JSON String
    &gt; DataModel
</code></pre>
<p>Yes, the last serialization is an overhead but it’s possibly a general approach. This can be made more optimized like this:</p><pre><code class="language-cmd"># Saving to blob
DataModel &gt; JSONWriter &gt; MemoryStream &gt; GZipStream 
    &gt; Upload byte [] to blob

# Reading from blob
Download byte[] from blob &gt; GZipStream &gt; MemoryStream
    &gt; JSONWriter &gt; DataModel
</code></pre>
<p>This can help resolve multiple serialization, de-serialization and OOM issues.</p>
<h3 id="md5-checks--remove-redundant-integrity-checks">MD5 Checks – remove redundant integrity checks</h3>
<p>Azure Storage Blob uses MD5 hash check for checking the integrity of data. This is done at different levels; In case of PUT operations – the MD5 is computed at the client and checked at the service and vice versa in case of GET operations. However, this is not needed if you enforce HTTPS only transport mechanism – which can be done in Azure Storage Blob. If HTTPS only is enabled then MD5 check is a redundant integrity check. It can be done in following way:</p>
<div class="language-csharp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">//// Upload data to blob</span>
<span class="k">public</span> <span class="k">void</span> <span class="nf">UploadData</span><span class="p">(</span><span class="n">DataModel</span> <span class="n">data</span><span class="p">,</span> <span class="kt">string</span> <span class="n">blobName</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">BlobRequestOptions</span> <span class="n">blobRequestOption</span> <span class="p">=</span> <span class="k">new</span> <span class="nf">BlobRequestOptions</span><span class="p">()</span>
  <span class="p">{</span>
      <span class="n">DisableContentMD5Validation</span> <span class="p">=</span> <span class="k">false</span>
  <span class="p">};</span>
            
  <span class="c1">//// define cloudBlobContainer above</span>
  <span class="n">CloudBlockBlob</span> <span class="n">blockBlob</span> <span class="p">=</span> <span class="n">cloudBlobContainer</span><span class="p">.</span><span class="nf">GetBlockBlobReference</span><span class="p">(</span><span class="n">blobName</span><span class="p">);</span>
  <span class="n">blockBlob</span><span class="p">.</span><span class="nf">UploadText</span><span class="p">(</span>
      <span class="n">JsonConvert</span><span class="p">.</span><span class="nf">SerializeObject</span><span class="p">(</span><span class="n">data</span><span class="p">),</span>
      <span class="n">options</span><span class="p">:</span> <span class="n">blobRequestOption</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">//// Upload data to blob</span>
<span class="k">public</span> <span class="n">DataModel</span> <span class="nf">DownloadData</span><span class="p">(</span><span class="kt">string</span> <span class="n">blobName</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">BlobRequestOptions</span> <span class="n">blobRequestOption</span> <span class="p">=</span> <span class="k">new</span> <span class="nf">BlobRequestOptions</span><span class="p">()</span>
  <span class="p">{</span>
      <span class="n">DisableContentMD5Validation</span> <span class="p">=</span> <span class="k">false</span>
  <span class="p">};</span>
            
  <span class="c1">//// define cloudBlobContainer above</span>
  <span class="n">CloudBlockBlob</span> <span class="n">blockBlob</span> <span class="p">=</span> <span class="n">cloudBlobContainer</span><span class="p">.</span><span class="nf">GetBlockBlobReference</span><span class="p">(</span><span class="n">blobName</span><span class="p">);</span>
  <span class="kt">string</span> <span class="n">data</span> <span class="p">=</span> <span class="n">blockBlob</span><span class="p">.</span><span class="nf">DownloadText</span><span class="p">(</span><span class="n">options</span><span class="p">:</span> <span class="n">blobRequestOption</span><span class="p">);</span>
  <span class="k">return</span> <span class="n">JsonConvert</span><span class="p">.</span><span class="n">DeserializeObject</span><span class="p">&lt;</span><span class="n">DataModel</span><span class="p">&gt;(</span><span class="n">data</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>
<h3 id="protocol-buffer">Protocol Buffer?</h3>
<p>I haven’t done much research on this topic but a top level reading suggests promising results. Following article may help further, I’ll perform some experiments and share the results:</p>
<ul>
 <li><a href="https://auth0.com/blog/beating-json-performance-with-protobuf/">https://auth0.com/blog/beating-json-performance-with-protobuf/</a></li>
 <li><a href="https://stackoverflow.com/questions/36477423/serializing-a-very-large-list-of-items-into-azure-blob-storage-using-c-sharp?utm_medium=organic&amp;utm_source=google_rich_qa&amp;utm_campaign=google_rich_qa">A decent stack-overflow read on this</a></li>
</ul>
<h2 id="references">References</h2>
<ol>
 <li><a href="https://stackoverflow.com/questions/49613999/how-to-serialize-a-large-object-zip-it-and-upload-to-azure-storage-blob-in-effi">StackOverflow question</a></li>
 <li>If you are consuming a type that uses unmanaged resources, you should be sure to call its <a href="https://msdn.microsoft.com/en-us/library/system.idisposable.dispose(v=vs.110).aspx">IDisposable.Dispose</a> method when you have finished using it.</li>
</ol>
 </div>
 <div class="post-footer">
<div class="related-posts">
  <span class="related-posts-text">Related posts:</span>
 <ul>
 </ul>
</div>
<div class="post-filed">
   <p class="post-meta">
      Filed under
<a class="category-link" href="/category/architecture/" rel="category">architecture</a>
<a class="category-link" href="/category/system-design/" rel="category">system-design</a>
<a class="category-link" href="/category/azure/" rel="category">azure</a>
<a class="category-link" href="/category/azure-storage-blob/" rel="category">azure-storage-blob</a>
<a class="category-link" href="/category/compression/" rel="category">compression</a>
<a class="category-link" href="/category/distributed-systems/" rel="category">distributed-systems</a>
<a class="category-link" href="/category/machine-learning/" rel="category">machine-learning</a>
<a class="category-link" href="/category/microsoft/" rel="category">microsoft</a>
   </p>
   <p>
      <a href="#top">top&nbsp;&#8673;</a>
   </p>
 </div>
<div class="post-nav">
   <p>
      <a href="/support-for-custom-logging-csrf-protector-library-and-more/">&#8672;&nbsp;Support for custom logging in CSRF Protector Library and more</a>
   </p>
   <p>
      <a href="/bypass-cell-size-limitation-of-azure-storage-table/">Bypass cell size limitation (64KB) of Azure Storage Table&nbsp;&#8674;</a>
   </p>
 </div>
<div style="border-top: 1px solid #cfcfcf; margin-top: 30px">
   <div class="widget-self">
   <div class="section-image">
        <a href="/about">
            <img src="/images/rsz_self_1_1.jpg" width="200px">
        </a>
   </div>
   <div class="section-info">
        <strong><a href="/about">Minhaz | Google | Singapore</a></strong>
       <div class="quote">
            I am working with Next Billion Users Org at Google. My team builds technologies for emerging markets.
            I feel, the goal of delivering cutting edge technologies to resource constrained devices with seamless performance is hard, at times frustating but worthwhile.
            Hoping for positive impact, good Karma and unbounded learning ;)
       </div>
       <div class="quote">
            These days I am working on #Computational-Photography and try hard at #Photography as well.
            I have good experience with #Distributed-Systems and #Applied-ML.
       </div>
   </div>
</div>
</div>
 </div>
 <div class="just-comments" data-apikey="014acd23-9a26-4415-a7ea-80f4253d1295" data-recaptcha="true"></div>
  <script async src="https://just-comments.com/w2.js"></script>
</article>
     </div>
   </main>
   <footer class="site-footer">
   <div class="wrapper-footer">
     <div class="footer-col-wrapper">
<a href="mailto:minhazav@gmail.com"><i class="svg-icon email"></i></a>
<a href="http://github.com/mebjas"><i class="svg-icon github"></i></a>
<a href="http://instagram.com/mebjas"><i class="svg-icon instagram"></i></a>
<a href="http://linkedin.com/in/https://www.linkedin.com/in/minhazav"><i class="svg-icon linkedin"></i></a>
<a href="http://twitter.com/minhazav"><i class="svg-icon twitter"></i></a>
<a href="http://stackoverflow.com/users/2614250/mebjas"><i class="svg-icon stackoverflow"></i></a>
     </div>
     <div class="copyright">
        © 2019 minhazav.dev
     </div>
   </div>
    <script src="/assets/js/anchorize.js"></script>
 </footer>
    <script src="/assets/js/instantpage.js" type="module" integrity="sha384-/IkE5iZAM/RxPto8B0nvKlMzIyCWtYocF01PbGGp1qElJuxv9J4whdWBRtzZltWn"></script>
 </body>
</html>
